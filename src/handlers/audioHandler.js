const languageService = require('../services/languageService');
const openaiService = require('../services/openaiService');
const databaseService = require('../services/databaseService');
const logger = require('../utils/logger');
const path = require('path');
const fs = require('fs-extra');
const axios = require('axios');
const { config } = require('../config/config');

class AudioHandler {

  /**
   * Handle voice messages
   */
  async handleVoice(ctx) {
    try {
      const userId = ctx.from.id;
      
      // Get user and settings
      const user = await databaseService.getUserByTelegramId(userId);
      if (!user) {
        await ctx.reply('‚ùå –ü–æ–º–∏–ª–∫–∞: –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–µ –∑–Ω–∞–π–¥–µ–Ω. –°–ø—Ä–æ–±—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /start');
        return;
      }

      const userSettings = user.languages;
      logger.info(`Processing voice message from user ${userId} (${user.isPremium ? 'Premium' : 'Free'})`);

      // Send processing message
      const processingMsg = await ctx.reply('üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\n‚è≥ –†–æ–∑–ø—ñ–∑–Ω–∞—é –º–æ–≤—É...');
      
      // Download audio file
      const audioPath = await this.downloadAudio(ctx);
      
      try {
        // Update processing message
        await ctx.telegram.editMessageText(
          ctx.chat.id, 
          processingMsg.message_id, 
          null, 
          'üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüîÑ –ü–µ—Ä–µ–∫–ª–∞–¥–∞—é...'
        );

        // Check if user can make translation (token limits)
        const canTranslate = await databaseService.canUserMakeTranslation(user._id, 150);
        if (!canTranslate) {
          const limits = user.getCurrentLimits();
          await ctx.telegram.editMessageText(
            ctx.chat.id,
            processingMsg.message_id,
            null,
            `‚ö†Ô∏è **–õ—ñ–º—ñ—Ç –≤–∏—á–µ—Ä–ø–∞–Ω–æ**\n\n${limits.type === 'premium' ? 'üëë' : 'üÜì'} –í–∏ –¥–æ—Å—è–≥–ª–∏ ${limits.type === 'premium' ? '–ø—Ä–µ–º—ñ—É–º' : '–±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ–≥–æ'} –ª—ñ–º—ñ—Ç—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è.\n\nüíé ${limits.type === 'free' ? '–†–æ–∑–≥–ª—è–¥–∞–π—Ç–µ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –ø—Ä–µ–º—ñ—É–º –ø—ñ–¥–ø–∏—Å–∫–∏ –¥–ª—è x10 –±—ñ–ª—å—à–∏—Ö –ª—ñ–º—ñ—Ç—ñ–≤!' : '–°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.'}`
          );
          return;
        }

        // Check if user is premium
        if (user.isPremium && user.hasPremiumFeature('autoLanguageDetection')) {
          // Premium users get automatic language detection with GPT enhancement
          await ctx.telegram.editMessageText(
            ctx.chat.id, 
            processingMsg.message_id, 
            null, 
            'üëë –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏ (GPT + Whisper)...'
          );
          
          const result = await openaiService.completeTranslationAuto(
            audioPath,
            userSettings.primaryLanguage,
            userSettings.secondaryLanguage,
            true // isPremium = true
          );

          // Update processing message
          await ctx.telegram.editMessageText(
            ctx.chat.id, 
            processingMsg.message_id, 
            null, 
            'üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüíæ –ó–±–µ—Ä—ñ–≥–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...'
          );

          // Update user stats and token usage
          await databaseService.incrementUserTranslations(user._id);
          await databaseService.addUserTokenUsage(user._id, result.tokensUsed || 150);

          // Format and send result
          await this.sendTranslationResult(ctx, result, user);
          
          // Delete processing message
          await ctx.telegram.deleteMessage(ctx.chat.id, processingMsg.message_id);
        } else {
          // Free users need to select language before speaking
          // Check if user has already selected language
          if (user.isWaitingForVoice() && user.voiceState.selectedInputLanguage) {
            // User has selected language, process directly
            const inputLang = user.voiceState.selectedInputLanguage;
            const outputLang = inputLang === userSettings.primaryLanguage ? 
              userSettings.secondaryLanguage : userSettings.primaryLanguage;

            await ctx.telegram.editMessageText(
              ctx.chat.id, 
              processingMsg.message_id, 
              null, 
              `üÜì –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüîÑ –ü–µ—Ä–µ–∫–ª–∞–¥–∞—é –∑ ${languageService.getLanguageInfo(inputLang).name}...`
            );

            try {
              // Process translation with known language (no language detection for free users)
              const result = await openaiService.completeTranslationManual(
                audioPath,
                inputLang,
                outputLang
              );

              // Update processing message
              await ctx.telegram.editMessageText(
                ctx.chat.id, 
                processingMsg.message_id, 
                null, 
                'üÜì –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüíæ –ó–±–µ—Ä—ñ–≥–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...'
              );

              // Update user stats and token usage
              await databaseService.incrementUserTranslations(user._id);
              await databaseService.addUserTokenUsage(user._id, result.tokensUsed || 150);

              // Clear voice state
              user.clearVoiceState();
              await user.save();

              // Format and send result
              await this.sendTranslationResult(ctx, result, user);
              
              // Delete processing message
              await ctx.telegram.deleteMessage(ctx.chat.id, processingMsg.message_id);

            } catch (error) {
              logger.error('Error processing free user translation:', error);
              await ctx.telegram.editMessageText(
                ctx.chat.id,
                processingMsg.message_id,
                null,
                '‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.'
              );
              user.clearVoiceState();
              await user.save();
            }
          } else {
            // Check if user has a last selected language
            if (user.voiceState.lastSelectedLanguage) {
              // Use last selected language automatically
              const inputLang = user.voiceState.lastSelectedLanguage;
              const outputLang = inputLang === userSettings.primaryLanguage ? 
                userSettings.secondaryLanguage : userSettings.primaryLanguage;

              await ctx.telegram.editMessageText(
                ctx.chat.id, 
                processingMsg.message_id, 
                null, 
                `üÜì –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüîÑ –ü–µ—Ä–µ–∫–ª–∞–¥–∞—é –∑ ${languageService.getLanguageInfo(inputLang).name}...`
              );

              try {
                // Process translation with last selected language
                const result = await openaiService.completeTranslationManual(
                  audioPath,
                  inputLang,
                  outputLang
                );

                // Update processing message
                await ctx.telegram.editMessageText(
                  ctx.chat.id, 
                  processingMsg.message_id, 
                  null, 
                  'üÜì –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüíæ –ó–±–µ—Ä—ñ–≥–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...'
                );

                // Update user stats and token usage
                await databaseService.incrementUserTranslations(user._id);
                await databaseService.addUserTokenUsage(user._id, result.tokensUsed || 150);

                // Format and send result
                await this.sendTranslationResult(ctx, result, user);
                
                // Delete processing message
                await ctx.telegram.deleteMessage(ctx.chat.id, processingMsg.message_id);

              } catch (error) {
                logger.error('Error processing free user translation with remembered language:', error);
                await ctx.telegram.editMessageText(
                  ctx.chat.id,
                  processingMsg.message_id,
                  null,
                  '‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.'
                );
              }
            } else {
              // User needs to select language first - show selection directly
              await ctx.telegram.editMessageText(
                ctx.chat.id,
                processingMsg.message_id,
                null,
                `üÜì **–°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä—ñ—Ç—å –º–æ–≤—É –¥–ª—è –¥–∏–∫—Ç—É–≤–∞–Ω–Ω—è**

‚ùó –î–ª—è –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ—ó –≤–µ—Ä—Å—ñ—ó –ø–æ—Ç—Ä—ñ–±–Ω–æ —Å–ø–æ—á–∞—Ç–∫—É –≤–∏–±—Ä–∞—Ç–∏ –º–æ–≤—É, –∞ –ø–æ—Ç—ñ–º –¥–∏–∫—Ç—É–≤–∞—Ç–∏.

üé§ –Ø–∫–æ—é –º–æ–≤–æ—é –≤–∏ –±—É–¥–µ—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç–∏?`,
                {
                  parse_mode: 'Markdown',
                  reply_markup: await this.getLanguageSelectionKeyboard(user)
                }
              );

              // Clean up the audio file since we can't process it now
              await this.cleanupAudioFile(audioPath);
            }
          }
        }

      } finally {
        // Clean up audio file only for premium users (free users need it for later processing)
        if (user.isPremium && user.hasPremiumFeature('autoLanguageDetection')) {
          await this.cleanupAudioFile(audioPath);
        }
      }

    } catch (error) {
      logger.error('Error processing voice message:', error);
      await ctx.reply('‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.');
    }
  }

  /**
   * Download audio file from Telegram
   */
  async downloadAudio(ctx) {
    try {
      const voice = ctx.message.voice;
      const fileId = voice.file_id;
      
      // Get file info from Telegram
      const fileInfo = await ctx.telegram.getFile(fileId);
      const fileUrl = `https://api.telegram.org/file/bot${config.telegram.token}/${fileInfo.file_path}`;
      
      // Generate unique filename
      const timestamp = Date.now();
      const fileName = `voice_${ctx.from.id}_${timestamp}.ogg`;
      const filePath = path.join(config.bot.tempAudioDir, fileName);
      
      // Ensure directory exists
      await fs.ensureDir(config.bot.tempAudioDir);
      
      // Download file
      const response = await axios({
        method: 'GET',
        url: fileUrl,
        responseType: 'stream'
      });
      
      const writer = fs.createWriteStream(filePath);
      response.data.pipe(writer);
      
      return new Promise((resolve, reject) => {
        writer.on('finish', () => {
          logger.info(`Audio file downloaded: ${filePath}`);
          resolve(filePath);
        });
        writer.on('error', reject);
      });

    } catch (error) {
      logger.error('Error downloading audio file:', error);
      throw error;
    }
  }

  /**
   * Send formatted translation result
   */
  async sendTranslationResult(ctx, result, user) {
    try {
      const detectedLang = languageService.getLanguageInfo(result.detectedLanguage);
      const targetLang = languageService.getLanguageInfo(result.targetLanguage);
      
      // Simple format: just translation and original
      const message = `${targetLang.flag} **${result.translated}**

üó£Ô∏è –û—Ä–∏–≥—ñ–Ω–∞–ª (${detectedLang.flag}): ${result.original}`;

      // Simple keyboard - just settings
      const keyboard = {
        inline_keyboard: [
          [
            {
              text: '‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è',
              callback_data: 'open_settings'
            }
          ]
        ]
      };

      await ctx.reply(message, {
        parse_mode: 'Markdown',
        reply_markup: keyboard
      });

      logger.info(`Simple translation sent for user ${ctx.from.id}`);
    } catch (error) {
      logger.error('Error sending translation result:', error);
      throw error;
    }
  }

  /**
   * Handle audio messages (MP3, etc.)
   */
  async handleAudio(ctx) {
    try {
      const userId = ctx.from.id;
      logger.info(`Processing audio message from user ${userId}`);
      
      // For now, redirect to voice handler
      // In the future, you might want to handle different audio formats differently
      await ctx.reply('üéµ –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (–Ω–µ –∞—É–¥—ñ–æ —Ñ–∞–π–ª) –¥–ª—è –∫—Ä–∞—â–æ—ó —è–∫–æ—Å—Ç—ñ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è.');
    } catch (error) {
      logger.error('Error handling audio message:', error);
      await ctx.reply('‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –∞—É–¥—ñ–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.');
    }
  }

  /**
   * Clean up temporary audio file
   */
  async cleanupAudioFile(filePath) {
    try {
      if (await fs.pathExists(filePath)) {
        await fs.remove(filePath);
        logger.info(`Cleaned up audio file: ${filePath}`);
      }
    } catch (error) {
      logger.error('Error cleaning up audio file:', error);
    }
  }

  /**
   * Get language selection keyboard for free users
   */
  async getLanguageSelectionKeyboard(user) {
    const userSettings = user.languages;
    const primaryLang = languageService.getLanguageInfo(userSettings.primaryLanguage);
    const secondaryLang = languageService.getLanguageInfo(userSettings.secondaryLanguage);
    
    // Check if user has a last selected language to highlight it
    const lastSelected = user.voiceState.lastSelectedLanguage;
    
    // Build buttons with last selected indicated
    const primaryText = lastSelected === userSettings.primaryLanguage ? 
      `‚úÖ ${primaryLang.flag} –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${primaryLang.name} (–æ—Å—Ç–∞–Ω–Ω—ñ–π —Ä–∞–∑)` :
      `${primaryLang.flag} –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${primaryLang.name}`;
      
    const secondaryText = lastSelected === userSettings.secondaryLanguage ? 
      `‚úÖ ${secondaryLang.flag} –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${secondaryLang.name} (–æ—Å—Ç–∞–Ω–Ω—ñ–π —Ä–∞–∑)` :
      `${secondaryLang.flag} –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${secondaryLang.name}`;

    return {
      inline_keyboard: [
        [
          {
            text: primaryText,
            callback_data: `set_voice_lang_${userSettings.primaryLanguage}`
          }
        ],
        [
          {
            text: secondaryText,
            callback_data: `set_voice_lang_${userSettings.secondaryLanguage}`
          }
        ],
        [
          {
            text: '‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –º–æ–≤',
            callback_data: 'open_settings'
          }
        ]
      ]
    };
  }

  /**
   * Show language selection for free users (DEPRECATED - use getLanguageSelectionKeyboard)
   */
  async showLanguageSelectionForFreeUser(ctx, user) {
    try {
      const userSettings = user.languages;
      const primaryLang = languageService.getLanguageInfo(userSettings.primaryLanguage);
      const secondaryLang = languageService.getLanguageInfo(userSettings.secondaryLanguage);

      const message = `üéØ **–û–±–µ—Ä—ñ—Ç—å –º–æ–≤—É –¥–ª—è –¥–∏–∫—Ç—É–≤–∞–Ω–Ω—è**

üé§ –Ø–∫–æ—é –º–æ–≤–æ—é –≤–∏ –±—É–¥–µ—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç–∏?

–ü—ñ—Å–ª—è –≤–∏–±–æ—Ä—É –º–æ–≤–∏ –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.`;

      await ctx.reply(message, {
        parse_mode: 'Markdown',
        reply_markup: await this.getLanguageSelectionKeyboard(user)
      });
    } catch (error) {
      logger.error('Error showing language selection for free user:', error);
    }
  }

  /**
   * Handle document messages (in case user sends audio as document)
   */
  async handleDocument(ctx) {
    try {
      const document = ctx.message.document;
      
      // Check if it's an audio file
      if (document.mime_type && document.mime_type.startsWith('audio/')) {
        await ctx.reply('üéµ –Ø –æ—Ç—Ä–∏–º–∞–≤ –∞—É–¥—ñ–æ —Ñ–∞–π–ª, –∞–ª–µ –¥–ª—è –∫—Ä–∞—â–æ—ó —è–∫–æ—Å—Ç—ñ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ –≥–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ –º—ñ–∫—Ä–æ—Ñ–æ–Ω –≤ Telegram.');
        
        // You could implement document audio processing here if needed
        // For now, we'll just suggest using voice messages
      } else {
        await ctx.reply('üìÑ –Ø –æ–±—Ä–æ–±–ª—è—é –ª–∏—à–µ –≥–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è. –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É.');
      }
    } catch (error) {
      logger.error('Error handling document:', error);
      await ctx.reply('‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞.');
    }
  }
}

module.exports = new AudioHandler(); 