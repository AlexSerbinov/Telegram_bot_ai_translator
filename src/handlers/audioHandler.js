const languageService = require('../services/languageService');
const openaiService = require('../services/openaiService');
const databaseService = require('../services/databaseService');
const logger = require('../utils/logger');
const path = require('path');
const fs = require('fs-extra');
const axios = require('axios');
const { config } = require('../config/config');

class AudioHandler {

  /**
   * Handle voice messages
   */
  async handleVoice(ctx) {
    try {
      const userId = ctx.from.id;
      
      // Get user and settings
      const user = await databaseService.getUserByTelegramId(userId);
      if (!user) {
        await ctx.reply('‚ùå –ü–æ–º–∏–ª–∫–∞: –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–µ –∑–Ω–∞–π–¥–µ–Ω. –°–ø—Ä–æ–±—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /start');
        return;
      }

      const userSettings = user.languages;
      logger.info(`Processing voice message from user ${userId} (${user.isPremium ? 'Premium' : 'Free'})`);

      // Send processing message
      const processingMsg = await ctx.reply('üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\n‚è≥ –†–æ–∑–ø—ñ–∑–Ω–∞—é –º–æ–≤—É...');
      
      // Download audio file
      const audioPath = await this.downloadAudio(ctx);
      
      try {
        // Update processing message
        await ctx.telegram.editMessageText(
          ctx.chat.id, 
          processingMsg.message_id, 
          null, 
          'üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüîÑ –ü–µ—Ä–µ–∫–ª–∞–¥–∞—é...'
        );

        // Check if user can make translation (token limits)
        const canTranslate = await databaseService.canUserMakeTranslation(user._id, 150);
        if (!canTranslate) {
          const limits = user.getCurrentLimits();
          await ctx.telegram.editMessageText(
            ctx.chat.id,
            processingMsg.message_id,
            null,
            `‚ö†Ô∏è **–õ—ñ–º—ñ—Ç –≤–∏—á–µ—Ä–ø–∞–Ω–æ**\n\n${limits.type === 'premium' ? 'üëë' : 'üÜì'} –í–∏ –¥–æ—Å—è–≥–ª–∏ ${limits.type === 'premium' ? '–ø—Ä–µ–º—ñ—É–º' : '–±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ–≥–æ'} –ª—ñ–º—ñ—Ç—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è.\n\nüíé ${limits.type === 'free' ? '–†–æ–∑–≥–ª—è–¥–∞–π—Ç–µ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –ø—Ä–µ–º—ñ—É–º –ø—ñ–¥–ø–∏—Å–∫–∏ –¥–ª—è x10 –±—ñ–ª—å—à–∏—Ö –ª—ñ–º—ñ—Ç—ñ–≤!' : '–°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.'}`
          );
          return;
        }

        // Check if user is premium
        if (user.isPremium && user.hasPremiumFeature('autoLanguageDetection')) {
          // Premium users get automatic language detection with GPT enhancement
          await ctx.telegram.editMessageText(
            ctx.chat.id, 
            processingMsg.message_id, 
            null, 
            'üëë –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüß† –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏ (GPT + Whisper)...'
          );
          
          const result = await openaiService.completeTranslationAuto(
            audioPath,
            userSettings.primaryLanguage,
            userSettings.secondaryLanguage,
            true // isPremium = true
          );

          // Update processing message
          await ctx.telegram.editMessageText(
            ctx.chat.id, 
            processingMsg.message_id, 
            null, 
            'üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüíæ –ó–±–µ—Ä—ñ–≥–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...'
          );

          // Update user stats and token usage
          await databaseService.incrementUserTranslations(user._id);
          await databaseService.addUserTokenUsage(user._id, result.tokensUsed || 150);

          // Format and send result
          await this.sendTranslationResult(ctx, result, user);
          
          // Delete processing message
          await ctx.telegram.deleteMessage(ctx.chat.id, processingMsg.message_id);
        } else {
          // Free users need to select language before speaking
          // Check if user has already selected language
          if (user.isWaitingForVoice() && user.voiceState.selectedInputLanguage) {
            // User has selected language, process directly
            const inputLang = user.voiceState.selectedInputLanguage;
            const outputLang = inputLang === userSettings.primaryLanguage ? 
              userSettings.secondaryLanguage : userSettings.primaryLanguage;

            await ctx.telegram.editMessageText(
              ctx.chat.id, 
              processingMsg.message_id, 
              null, 
              `üÜì –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüé§ –†–æ–∑–ø—ñ–∑–Ω–∞—é –º–æ–≤—É (${languageService.getLanguageInfo(inputLang).name})...`
            );

            try {
              // Process translation with known language
              const result = await openaiService.completeTranslationManual(
                audioPath,
                inputLang,
                outputLang
              );

              // Update processing message
              await ctx.telegram.editMessageText(
                ctx.chat.id, 
                processingMsg.message_id, 
                null, 
                'üÜì –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...\nüíæ –ó–±–µ—Ä—ñ–≥–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...'
              );

              // Update user stats and token usage
              await databaseService.incrementUserTranslations(user._id);
              await databaseService.addUserTokenUsage(user._id, result.tokensUsed || 150);

              // Clear voice state
              user.clearVoiceState();
              await user.save();

              // Format and send result
              await this.sendTranslationResult(ctx, result, user);
              
              // Delete processing message
              await ctx.telegram.deleteMessage(ctx.chat.id, processingMsg.message_id);

            } catch (error) {
              logger.error('Error processing free user translation:', error);
              await ctx.telegram.editMessageText(
                ctx.chat.id,
                processingMsg.message_id,
                null,
                '‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.'
              );
              user.clearVoiceState();
              await user.save();
            }
          } else {
            // User needs to select language first
            await ctx.telegram.editMessageText(
              ctx.chat.id,
              processingMsg.message_id,
              null,
              `üÜì **–°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä—ñ—Ç—å –º–æ–≤—É –¥–ª—è –¥–∏–∫—Ç—É–≤–∞–Ω–Ω—è**

‚ùó –î–ª—è –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ—ó –≤–µ—Ä—Å—ñ—ó –ø–æ—Ç—Ä—ñ–±–Ω–æ —Å–ø–æ—á–∞—Ç–∫—É –≤–∏–±—Ä–∞—Ç–∏ –º–æ–≤—É, –∞ –ø–æ—Ç—ñ–º –¥–∏–∫—Ç—É–≤–∞—Ç–∏.

–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–Ω–æ–ø–∫—É "üéØ –û–±—Ä–∞—Ç–∏ –º–æ–≤—É" –Ω–∏–∂—á–µ:`
            );

            // Clean up the audio file since we can't process it now
            await this.cleanupAudioFile(audioPath);

            // Show language selection buttons
            setTimeout(async () => {
              await this.showLanguageSelectionForFreeUser(ctx, user);
            }, 2000);
          }
        }

      } finally {
        // Clean up audio file only for premium users (free users need it for later processing)
        if (user.isPremium && user.hasPremiumFeature('autoLanguageDetection')) {
          await this.cleanupAudioFile(audioPath);
        }
      }

    } catch (error) {
      logger.error('Error processing voice message:', error);
      await ctx.reply('‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.');
    }
  }

  /**
   * Download audio file from Telegram
   */
  async downloadAudio(ctx) {
    try {
      const voice = ctx.message.voice;
      const fileId = voice.file_id;
      
      // Get file info from Telegram
      const fileInfo = await ctx.telegram.getFile(fileId);
      const fileUrl = `https://api.telegram.org/file/bot${config.telegram.token}/${fileInfo.file_path}`;
      
      // Generate unique filename
      const timestamp = Date.now();
      const fileName = `voice_${ctx.from.id}_${timestamp}.ogg`;
      const filePath = path.join(config.bot.tempAudioDir, fileName);
      
      // Ensure directory exists
      await fs.ensureDir(config.bot.tempAudioDir);
      
      // Download file
      const response = await axios({
        method: 'GET',
        url: fileUrl,
        responseType: 'stream'
      });
      
      const writer = fs.createWriteStream(filePath);
      response.data.pipe(writer);
      
      return new Promise((resolve, reject) => {
        writer.on('finish', () => {
          logger.info(`Audio file downloaded: ${filePath}`);
          resolve(filePath);
        });
        writer.on('error', reject);
      });

    } catch (error) {
      logger.error('Error downloading audio file:', error);
      throw error;
    }
  }

  /**
   * Send formatted translation result
   */
  async sendTranslationResult(ctx, result, user) {
    try {
      const detectedLang = languageService.getLanguageInfo(result.detectedLanguage);
      const targetLang = languageService.getLanguageInfo(result.targetLanguage);
      const primaryLang = languageService.getLanguageInfo(user.languages.primaryLanguage);
      const secondaryLang = languageService.getLanguageInfo(user.languages.secondaryLanguage);
      
      // Build main translation message
      let message = `üåç **${targetLang.flag} –ü–ï–†–ï–ö–õ–ê–î:**
**${result.translated}**

üé§ *–†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ* (${detectedLang.flag} ${detectedLang.name}):
${result.original}`;

      // Add back-translation for Premium users only
      if (result.isPremium && result.backTranslation) {
        message += `\n\nüîÑ *–ó–≤–æ—Ä–æ—Ç–Ω—ñ–π –ø–µ—Ä–µ–∫–ª–∞–¥* (${detectedLang.flag} ${detectedLang.name}):
${result.backTranslation}`;
      }

      // Add language detection info based on user type
      let detectionInfo = '';
      if (result.isPremium && result.whisperDetection && result.gptDetection) {
        const whisperLang = languageService.getLanguageInfo(result.whisperDetection);
        const gptLang = languageService.getLanguageInfo(result.gptDetection);
        
        if (result.whisperDetection === result.gptDetected) {
          detectionInfo = `\nüîç *–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è:* üëë Whisper + GPT –ø–æ–≥–æ–¥–∏–ª–∏—Å—å: ${detectedLang.flag} ${detectedLang.name}`;
        } else {
          detectionInfo = `\nüîç *–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è:* üëë Whisper: ${whisperLang.flag} ${whisperLang.name}, GPT: ${gptLang.flag} ${gptLang.name} ‚Üí ${detectedLang.flag} ${detectedLang.name}`;
        }
      } else if (!result.isPremium) {
        detectionInfo = `\nüîç *–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è:* üÜì –ë–∞–∑–æ–≤–µ (—Ç—ñ–ª—å–∫–∏ Whisper)`;
      }

      // Add user info and statistics
      message += `\n\nü§ñ *–í–∞—à—ñ –º–æ–≤–∏:* ${primaryLang.flag} ${primaryLang.name} ‚áÑ ${secondaryLang.flag} ${secondaryLang.name}
üìä *–í—Å—å–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤:* ${user.stats.totalTranslations + 1}${detectionInfo}`;

      // Add subscription info and features
      if (result.isPremium) {
        message += `\n\nüëë **–ü–†–ï–ú–Ü–£–ú –§–£–ù–ö–¶–Ü–á:**
‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏ (GPT + Whisper)
‚úÖ –ó–≤–æ—Ä–æ—Ç–Ω—ñ–π –ø–µ—Ä–µ–∫–ª–∞–¥ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
‚úÖ x10 –±—ñ–ª—å—à–µ –ª—ñ–º—ñ—Ç—ñ–≤ —Ç–æ–∫–µ–Ω—ñ–≤`;
      } else {
        message += `\n\nüÜì **–ë–ï–ó–ö–û–®–¢–û–í–ù–ê –í–ï–†–°–Ü–Ø**
üí° –ü—Ä–µ–º—ñ—É–º —Ñ—É–Ω–∫—Ü—ñ—ó –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ:
‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏
‚Ä¢ –ó–≤–æ—Ä–æ—Ç–Ω—ñ–π –ø–µ—Ä–µ–∫–ª–∞–¥
‚Ä¢ –ó–±—ñ–ª—å—à–µ–Ω—ñ –ª—ñ–º—ñ—Ç–∏`;
      }

      // Build different keyboards for Premium and Free users
      let keyboard;
      if (result.isPremium) {
        // Premium users get language switching and limits
        keyboard = {
          inline_keyboard: [
            [
              {
                text: `üîÑ ${primaryLang.flag} ‚áÑ ${secondaryLang.flag} –ü–æ–º—ñ–Ω—è—Ç–∏ –º–æ–≤–∏`,
                callback_data: 'switch_languages'
              }
            ],
            [
              {
                text: 'üìä –ú–æ—ó –ª—ñ–º—ñ—Ç–∏',
                callback_data: 'show_limits'
              },
              {
                text: '‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è',
                callback_data: 'open_settings'
              }
            ]
          ]
        };
      } else {
        // Free users get dictation buttons for next translation
        keyboard = {
          inline_keyboard: [
            [
              {
                text: `üé§ –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${primaryLang.flag}`,
                callback_data: `set_voice_lang_${user.languages.primaryLanguage}`
              },
              {
                text: `üé§ –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${secondaryLang.flag}`,
                callback_data: `set_voice_lang_${user.languages.secondaryLanguage}`
              }
            ],
            [
              {
                text: 'üìä –ú–æ—ó –ª—ñ–º—ñ—Ç–∏',
                callback_data: 'show_limits'
              },
              {
                text: 'üíé –ü—Ä–µ–º—ñ—É–º',
                callback_data: 'upgrade_premium'
              }
            ]
          ]
        };
      }

      await ctx.reply(message, {
        parse_mode: 'Markdown',
        reply_markup: keyboard
      });

      logger.info(`${result.isPremium ? 'Premium' : 'Free'} translation sent for user ${ctx.from.id}`);
    } catch (error) {
      logger.error('Error sending translation result:', error);
      throw error;
    }
  }

  /**
   * Handle audio messages (MP3, etc.)
   */
  async handleAudio(ctx) {
    try {
      const userId = ctx.from.id;
      logger.info(`Processing audio message from user ${userId}`);
      
      // For now, redirect to voice handler
      // In the future, you might want to handle different audio formats differently
      await ctx.reply('üéµ –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (–Ω–µ –∞—É–¥—ñ–æ —Ñ–∞–π–ª) –¥–ª—è –∫—Ä–∞—â–æ—ó —è–∫–æ—Å—Ç—ñ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è.');
    } catch (error) {
      logger.error('Error handling audio message:', error);
      await ctx.reply('‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –∞—É–¥—ñ–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.');
    }
  }

  /**
   * Clean up temporary audio file
   */
  async cleanupAudioFile(filePath) {
    try {
      if (await fs.pathExists(filePath)) {
        await fs.remove(filePath);
        logger.info(`Cleaned up audio file: ${filePath}`);
      }
    } catch (error) {
      logger.error('Error cleaning up audio file:', error);
    }
  }

  /**
   * Show language selection for free users
   */
  async showLanguageSelectionForFreeUser(ctx, user) {
    try {
      const userSettings = user.languages;
      const primaryLang = languageService.getLanguageInfo(userSettings.primaryLanguage);
      const secondaryLang = languageService.getLanguageInfo(userSettings.secondaryLanguage);

      const message = `üéØ **–û–±–µ—Ä—ñ—Ç—å –º–æ–≤—É –¥–ª—è –¥–∏–∫—Ç—É–≤–∞–Ω–Ω—è**

üé§ –Ø–∫–æ—é –º–æ–≤–æ—é –≤–∏ –±—É–¥–µ—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç–∏?

–ü—ñ—Å–ª—è –≤–∏–±–æ—Ä—É –º–æ–≤–∏ –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.`;

      await ctx.reply(message, {
        parse_mode: 'Markdown',
        reply_markup: {
          inline_keyboard: [
            [
              {
                text: `${primaryLang.flag} –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${primaryLang.name}`,
                callback_data: `set_voice_lang_${userSettings.primaryLanguage}`
              }
            ],
            [
              {
                text: `${secondaryLang.flag} –î–∏–∫—Ç—É–≤–∞—Ç–∏ ${secondaryLang.name}`,
                callback_data: `set_voice_lang_${userSettings.secondaryLanguage}`
              }
            ],
            [
              {
                text: '‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –º–æ–≤',
                callback_data: 'open_settings'
              }
            ]
          ]
        }
      });
    } catch (error) {
      logger.error('Error showing language selection for free user:', error);
    }
  }

  /**
   * Handle document messages (in case user sends audio as document)
   */
  async handleDocument(ctx) {
    try {
      const document = ctx.message.document;
      
      // Check if it's an audio file
      if (document.mime_type && document.mime_type.startsWith('audio/')) {
        await ctx.reply('üéµ –Ø –æ—Ç—Ä–∏–º–∞–≤ –∞—É–¥—ñ–æ —Ñ–∞–π–ª, –∞–ª–µ –¥–ª—è –∫—Ä–∞—â–æ—ó —è–∫–æ—Å—Ç—ñ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ –≥–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ –º—ñ–∫—Ä–æ—Ñ–æ–Ω –≤ Telegram.');
        
        // You could implement document audio processing here if needed
        // For now, we'll just suggest using voice messages
      } else {
        await ctx.reply('üìÑ –Ø –æ–±—Ä–æ–±–ª—è—é –ª–∏—à–µ –≥–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è. –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É.');
      }
    } catch (error) {
      logger.error('Error handling document:', error);
      await ctx.reply('‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞.');
    }
  }
}

module.exports = new AudioHandler(); 